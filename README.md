# üéµ Real-Time Music Regulator

**A Digital Therapeutic (DTx) Demonstration for Adaptive Music Therapy**

---

## üìã Project Overview

The Real-Time Music Regulator is a portfolio-ready demonstration of an evidence-based, adaptive music intervention system. It showcases how AI/ML and biofeedback can be integrated to deliver personalized music therapy in real-time.

### Key Features

- üß† **Simulated Biofeedback**: Realistic physiological data generation (heart rate, HRV, arousal, valence)
- üéº **Adaptive Music Engine**: Three therapeutic algorithms (ISO-principle, entrainment, progressive)
- ü§ñ **AI Emotion Recognition**: Multi-modal emotion classification (physiological + facial simulation)
- üìä **Real-Time Adaptation**: Music parameters adjust dynamically based on patient state
- üè• **Clinical Grounding**: Evidence-based design following music therapy research

---

## üèóÔ∏è Architecture

### Current Structure (v0.2.0)

```
music-regulator/
‚îú‚îÄ‚îÄ memlog/                          # Project tracking & documentation
‚îÇ   ‚îú‚îÄ‚îÄ tasks.log                    # Task management
‚îÇ   ‚îú‚îÄ‚îÄ changelog.md                 # Development history
‚îÇ   ‚îú‚îÄ‚îÄ file_dependencies.md         # Module relationships
‚îÇ   ‚îú‚îÄ‚îÄ stability_checklist.md       # Quality assurance
‚îÇ   ‚îî‚îÄ‚îÄ potential_issues.md          # Risk tracking
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ biofeedback-profiles.json    # Physiological state profiles
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ simulators/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BiofeedbackSimulator.ts      # Realistic biosignal generation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ EmotionRecognition.ts        # AI emotion classification (simulated)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ music/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AdaptiveMusicEngine.ts       # Core therapeutic music adaptation
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ai/                              # [PLANNED] ML simulation layer
‚îÇ   ‚îî‚îÄ‚îÄ components/                      # [PLANNED] React components
‚îÇ
‚îú‚îÄ‚îÄ docs/                                # [PLANNED] Technical documentation
‚îú‚îÄ‚îÄ index.html                           # Original demo (to be refactored)
‚îî‚îÄ‚îÄ README.md                            # This file
```

---

## üî¨ Technical Components

### 1. Biofeedback Simulation (`src/simulators/BiofeedbackSimulator.ts`)

**Purpose**: Generate realistic physiological data streams

**Features**:
- 6 predefined emotional states (relaxed, focused, stressed, anxious, energized, fatigued)
- Natural variability using noise generation
- Smooth transitions between states
- Scenario-based playback (e.g., 30-minute stress reduction session)

**Metrics Simulated**:
- Heart Rate (BPM)
- Heart Rate Variability (HRV)
- Arousal Level (0-100)
- Valence (emotional positivity, 0-100)
- Respiration Rate
- Skin Conductance
- Muscle Tension

**Usage Example**:
```typescript
const simulator = new BiofeedbackSimulator('focused');
simulator.subscribe((reading) => {
  console.log(reading.heartRate, reading.arousal);
});
simulator.start();
simulator.transitionTo('relaxed'); // Smooth 50-second transition
```

### 2. Emotion Recognition (`src/simulators/EmotionRecognition.ts`)

**Purpose**: Simulate AI-powered emotion detection from biofeedback

**Features**:
- Arousal-valence model for emotion classification
- Multi-modal fusion (physiological + facial)
- Confidence scores with realistic variability
- Trend analysis over time

**Emotion Categories**:
- Happy, Sad, Anxious, Calm, Focused, Frustrated, Energized

**Usage Example**:
```typescript
const recognizer = new EmotionRecognizer();
const prediction = await recognizer.recognizeMultimodal(biofeedbackReading);
console.log(prediction.emotion, prediction.confidence);
```

### 3. Adaptive Music Engine (`src/music/AdaptiveMusicEngine.ts`)

**Purpose**: Generate therapeutic music parameters based on biofeedback

**Therapeutic Algorithms**:

1. **ISO-Principle** (Default)
   - Matches current emotional state
   - Gradually guides toward therapeutic target
   - Evidence: Most effective for stress/anxiety reduction

2. **Entrainment**
   - Directly sets target physiological state via music
   - Evidence: Effective for sleep induction, meditation

3. **Progressive**
   - Step-wise adaptation based on biofeedback trends
   - Evidence: Good for long-term monitoring sessions

**Music Parameters Controlled**:
- Tempo (BPM)
- Harmony (consonant/complex/dissonant)
- Volume
- Note Density
- Timbre (soft/neutral/bright)
- Rhythm Complexity

**Therapeutic Goals**:
- Relaxation
- Focus Enhancement
- Energy Boost
- Mood Elevation

**Usage Example**:
```typescript
const engine = new AdaptiveMusicEngine({ 
  type: 'relaxation', 
  intensity: 70 
});
engine.setAlgorithm('iso_principle');

const params = engine.update(biofeedbackReading);
// Apply params.tempo, params.harmony, etc. to audio engine
```

---

## üìä Biofeedback Profiles

Six clinically-inspired emotional states:

| Profile | Arousal | Valence | HR (bpm) | Use Case |
|---------|---------|---------|----------|----------|
| **Relaxed** | 20 | 80 | 65 | Meditation baseline |
| **Focused** | 45 | 60 | 72 | Productive work state |
| **Stressed** | 85 | 30 | 95 | Acute stress response |
| **Anxious** | 75 | 35 | 88 | Chronic worry |
| **Energized** | 80 | 75 | 92 | Positive arousal |
| **Fatigued** | 25 | 35 | 70 | Mental exhaustion |

---

## üéØ Therapeutic Scenarios

Pre-defined intervention timelines:

1. **Stress Reduction** (30 min)
   - Stressed ‚Üí Anxious ‚Üí Focused ‚Üí Relaxed
   - Demonstrates ISO-principle effectiveness

2. **Focus Enhancement** (15 min)
   - Fatigued ‚Üí Focused (sustained)
   - Demonstrates entrainment for concentration

3. **Anxiety Management** (20 min)
   - Anxious ‚Üí Focused ‚Üí Relaxed
   - Progressive calming intervention

---

## üöÄ Roadmap

### Phase 1: Core Foundation ‚úÖ (Current)
- [x] Memlog system setup
- [x] Biofeedback simulation
- [x] Emotion recognition simulation
- [x] Adaptive music engine

### Phase 2: AI/ML Layer (In Progress)
- [ ] Playlist recommendation system
- [ ] Reinforcement learning simulation
- [ ] Personalization engine

### Phase 3: Portfolio Integration
- [ ] Next.js portfolio website
- [ ] React component refactoring
- [ ] Interactive demo embedding
- [ ] Project showcase page

### Phase 4: Enhancement
- [ ] Real Tone.js integration
- [ ] Data visualization dashboard
- [ ] Session analytics
- [ ] Clinical documentation

### Phase 5: Future (Real ML Integration)
- [ ] Python backend (Flask/FastAPI)
- [ ] Real emotion detection models
- [ ] Spotify API integration
- [ ] User personalization learning

---

## üß™ Development Principles

Following user-defined rules (`.clinerules`):

1. **File Size Limit**: Max 400 lines per file
2. **Modular Design**: Clear separation of concerns
3. **Documentation**: Comprehensive inline comments
4. **Error Handling**: Graceful degradation
5. **Type Safety**: TypeScript strict mode

---

## üìö Clinical Evidence Base

This project draws from:

- **Music Therapy Research**: Tempo-heart rate entrainment, harmonic tension effects
- **Affective Computing**: Arousal-valence circumplex model
- **Biofeedback Therapy**: Real-time physiological monitoring
- **Digital Therapeutics**: Evidence-based intervention design

**Note**: This is a demonstration/proof-of-concept. No clinical validation has been performed.

---

## üîí Privacy & Security

- **Simulated Data Only**: No real patient data collected
- **HIPAA-Aligned Design**: Architecture follows privacy principles
- **Transparent Simulation**: Clear labeling of AI/ML simulation vs real models

---

## üõ†Ô∏è Technology Stack

**Current**:
- TypeScript (type safety)
- JSON (data storage)
- Modular ES6+ architecture

**Planned**:
- Next.js 14+ (React framework)
- Tailwind CSS (styling)
- Tone.js (audio synthesis)
- Framer Motion (animations)

---

## üìñ Getting Started

**Prerequisites**: Modern browser with ES6+ support

**Current Demo**:
```bash
# Open in browser
open index.html
```

**Future (Next.js)**:
```bash
npm install
npm run dev
```

---

## üë§ Author

Portfolio project demonstrating expertise in:
- Digital Health / Digital Therapeutics
- AI/ML Integration
- Music Technology
- Evidence-Based Design

---

## üìÑ License

Portfolio demonstration project - All rights reserved

---

## üôè Acknowledgments

- Music therapy research community
- Open-source audio/ML libraries
- Evidence-based healthcare practitioners

---

**Last Updated**: 2025-06-12  
**Version**: 0.2.0  
**Status**: Active Development
